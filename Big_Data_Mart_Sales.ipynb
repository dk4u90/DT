{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Big Data Mart Sales.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXuv3CYpZ1SN"
      },
      "source": [
        "## Problem statement:\n",
        "The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined.\n",
        "\n",
        "Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing the sales of their products.\n",
        "\n",
        "## Predictions:\n",
        "The aim is to build a predictive model and find out the sales of each product at a particular store."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6R9_dKdx9ML"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "IVZ-N6YXy1dO",
        "outputId": "0a0cb8cd-c77c-4b44-e137-88392e31e1aa"
      },
      "source": [
        "test=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/bigdatamart_rep/master/bigdatamart_Test.csv\")\n",
        "train=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/bigdatamart_rep/master/bigdatamart_Train.csv\")\n",
        "train[\"source\"]=\"train\"\n",
        "test[\"source\"]=\"test\"\n",
        "data=pd.concat([train,test],ignore_index=True)\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Identifier</th>\n",
              "      <th>Item_Weight</th>\n",
              "      <th>Item_Fat_Content</th>\n",
              "      <th>Item_Visibility</th>\n",
              "      <th>Item_Type</th>\n",
              "      <th>Item_MRP</th>\n",
              "      <th>Outlet_Identifier</th>\n",
              "      <th>Outlet_Establishment_Year</th>\n",
              "      <th>Outlet_Size</th>\n",
              "      <th>Outlet_Location_Type</th>\n",
              "      <th>Outlet_Type</th>\n",
              "      <th>Item_Outlet_Sales</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDA15</td>\n",
              "      <td>9.30</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.016047</td>\n",
              "      <td>Dairy</td>\n",
              "      <td>249.8092</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 1</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>3735.1380</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DRC01</td>\n",
              "      <td>5.92</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.019278</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>48.2692</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>2009</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Supermarket Type2</td>\n",
              "      <td>443.4228</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FDN15</td>\n",
              "      <td>17.50</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.016760</td>\n",
              "      <td>Meat</td>\n",
              "      <td>141.6180</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 1</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>2097.2700</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FDX07</td>\n",
              "      <td>19.20</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Fruits and Vegetables</td>\n",
              "      <td>182.0950</td>\n",
              "      <td>OUT010</td>\n",
              "      <td>1998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Grocery Store</td>\n",
              "      <td>732.3800</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCD19</td>\n",
              "      <td>8.93</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Household</td>\n",
              "      <td>53.8614</td>\n",
              "      <td>OUT013</td>\n",
              "      <td>1987</td>\n",
              "      <td>High</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>994.7052</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14199</th>\n",
              "      <td>FDB58</td>\n",
              "      <td>10.50</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.013496</td>\n",
              "      <td>Snack Foods</td>\n",
              "      <td>141.3154</td>\n",
              "      <td>OUT046</td>\n",
              "      <td>1997</td>\n",
              "      <td>Small</td>\n",
              "      <td>Tier 1</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14200</th>\n",
              "      <td>FDD47</td>\n",
              "      <td>7.60</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.142991</td>\n",
              "      <td>Starchy Foods</td>\n",
              "      <td>169.1448</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>2009</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Supermarket Type2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14201</th>\n",
              "      <td>NCO17</td>\n",
              "      <td>10.00</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>Health and Hygiene</td>\n",
              "      <td>118.7440</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>2002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tier 2</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14202</th>\n",
              "      <td>FDJ26</td>\n",
              "      <td>15.30</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Canned</td>\n",
              "      <td>214.6218</td>\n",
              "      <td>OUT017</td>\n",
              "      <td>2007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tier 2</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14203</th>\n",
              "      <td>FDU37</td>\n",
              "      <td>9.50</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.104720</td>\n",
              "      <td>Canned</td>\n",
              "      <td>79.7960</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>2002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tier 2</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14204 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Item_Identifier  Item_Weight  ... Item_Outlet_Sales  source\n",
              "0               FDA15         9.30  ...         3735.1380   train\n",
              "1               DRC01         5.92  ...          443.4228   train\n",
              "2               FDN15        17.50  ...         2097.2700   train\n",
              "3               FDX07        19.20  ...          732.3800   train\n",
              "4               NCD19         8.93  ...          994.7052   train\n",
              "...               ...          ...  ...               ...     ...\n",
              "14199           FDB58        10.50  ...               NaN    test\n",
              "14200           FDD47         7.60  ...               NaN    test\n",
              "14201           NCO17        10.00  ...               NaN    test\n",
              "14202           FDJ26        15.30  ...               NaN    test\n",
              "14203           FDU37         9.50  ...               NaN    test\n",
              "\n",
              "[14204 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CS-EgHrafzh"
      },
      "source": [
        "Read the dataset of train and test and combined together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cU8dJKo0Iic",
        "outputId": "ede70f77-ca92-4235-e778-8cb47d1d3eaa"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Item_Identifier                 0\n",
              "Item_Weight                  2439\n",
              "Item_Fat_Content                0\n",
              "Item_Visibility                 0\n",
              "Item_Type                       0\n",
              "Item_MRP                        0\n",
              "Outlet_Identifier               0\n",
              "Outlet_Establishment_Year       0\n",
              "Outlet_Size                  4016\n",
              "Outlet_Location_Type            0\n",
              "Outlet_Type                     0\n",
              "Item_Outlet_Sales            5681\n",
              "source                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ky1v8_Ucqw-"
      },
      "source": [
        "Null value is present in columns Item_Weight, Outlet_Size and Item_Outlet_Sales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCuO6puE0nbt",
        "outputId": "51165025-5187-40e5-b296-fccddb9c1d7d"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14204 entries, 0 to 14203\n",
            "Data columns (total 13 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Item_Identifier            14204 non-null  object \n",
            " 1   Item_Weight                11765 non-null  float64\n",
            " 2   Item_Fat_Content           14204 non-null  object \n",
            " 3   Item_Visibility            14204 non-null  float64\n",
            " 4   Item_Type                  14204 non-null  object \n",
            " 5   Item_MRP                   14204 non-null  float64\n",
            " 6   Outlet_Identifier          14204 non-null  object \n",
            " 7   Outlet_Establishment_Year  14204 non-null  int64  \n",
            " 8   Outlet_Size                10188 non-null  object \n",
            " 9   Outlet_Location_Type       14204 non-null  object \n",
            " 10  Outlet_Type                14204 non-null  object \n",
            " 11  Item_Outlet_Sales          8523 non-null   float64\n",
            " 12  source                     14204 non-null  object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Ey2PLBdD7T"
      },
      "source": [
        "Displayed more informations of dataset.There are three datatype (float64=4, int64=1, object=8) is present in dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NDVaCCEQ0u2V",
        "outputId": "8fd52ee1-c875-4c48-cc71-80bedf266186"
      },
      "source": [
        "data.corr()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Weight</th>\n",
              "      <th>Item_Visibility</th>\n",
              "      <th>Item_MRP</th>\n",
              "      <th>Outlet_Establishment_Year</th>\n",
              "      <th>Item_Outlet_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Item_Weight</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015901</td>\n",
              "      <td>0.036236</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>0.014123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Item_Visibility</th>\n",
              "      <td>-0.015901</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006351</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-0.128625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Item_MRP</th>\n",
              "      <td>0.036236</td>\n",
              "      <td>-0.006351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.567574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outlet_Establishment_Year</th>\n",
              "      <td>0.000645</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.049135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Item_Outlet_Sales</th>\n",
              "      <td>0.014123</td>\n",
              "      <td>-0.128625</td>\n",
              "      <td>0.567574</td>\n",
              "      <td>-0.049135</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Item_Weight  ...  Item_Outlet_Sales\n",
              "Item_Weight                   1.000000  ...           0.014123\n",
              "Item_Visibility              -0.015901  ...          -0.128625\n",
              "Item_MRP                      0.036236  ...           0.567574\n",
              "Outlet_Establishment_Year     0.000645  ...          -0.049135\n",
              "Item_Outlet_Sales             0.014123  ...           1.000000\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPsbSOAod2yd"
      },
      "source": [
        "All the variables have very less correlation between each other\n",
        "\n",
        "Only exception is Item_MRP and Item_Outlet_Sales which shows significant correlation of 0.56"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZfS2bpf1HGL",
        "outputId": "7e477215-fb89-4643-ff5d-0d4147dbd4ec"
      },
      "source": [
        "for column in data.columns:\n",
        "  if data[column].dtype=='object':\n",
        "    print(\"column name is: {} and number of distict values: {}\".format(column,len(data[column].value_counts())))\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "column name is: Item_Identifier and number of distict values: 1559\n",
            "\n",
            "column name is: Item_Fat_Content and number of distict values: 5\n",
            "\n",
            "column name is: Item_Type and number of distict values: 16\n",
            "\n",
            "column name is: Outlet_Identifier and number of distict values: 10\n",
            "\n",
            "column name is: Outlet_Size and number of distict values: 3\n",
            "\n",
            "column name is: Outlet_Location_Type and number of distict values: 3\n",
            "\n",
            "column name is: Outlet_Type and number of distict values: 4\n",
            "\n",
            "column name is: source and number of distict values: 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeySbdzBeC3M"
      },
      "source": [
        "Based on below output we see there are 1559 values in item_identifier,we can drop as it is not so important variable\n",
        "\n",
        "Also if we keep it will increase the columns by 1559 when we will use one hot encoding\n",
        "\n",
        "Similary outlet identifier also can be removed from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC5JgVdV1tjC",
        "outputId": "217ec035-6651-44b3-8da1-8ad07835718b"
      },
      "source": [
        "for column in data.columns:\n",
        "    if data[column].dtype==\"object\":\n",
        "        print(data[column].value_counts())\n",
        "        print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FDL12    10\n",
            "FDU26    10\n",
            "DRG48    10\n",
            "NCD43    10\n",
            "FDP09    10\n",
            "         ..\n",
            "FDM10     7\n",
            "FDM50     7\n",
            "DRN11     7\n",
            "FDM52     7\n",
            "FDL50     7\n",
            "Name: Item_Identifier, Length: 1559, dtype: int64\n",
            "\n",
            "Low Fat    8485\n",
            "Regular    4824\n",
            "LF          522\n",
            "reg         195\n",
            "low fat     178\n",
            "Name: Item_Fat_Content, dtype: int64\n",
            "\n",
            "Fruits and Vegetables    2013\n",
            "Snack Foods              1989\n",
            "Household                1548\n",
            "Frozen Foods             1426\n",
            "Dairy                    1136\n",
            "Baking Goods             1086\n",
            "Canned                   1084\n",
            "Health and Hygiene        858\n",
            "Meat                      736\n",
            "Soft Drinks               726\n",
            "Breads                    416\n",
            "Hard Drinks               362\n",
            "Others                    280\n",
            "Starchy Foods             269\n",
            "Breakfast                 186\n",
            "Seafood                    89\n",
            "Name: Item_Type, dtype: int64\n",
            "\n",
            "OUT027    1559\n",
            "OUT013    1553\n",
            "OUT035    1550\n",
            "OUT046    1550\n",
            "OUT049    1550\n",
            "OUT045    1548\n",
            "OUT018    1546\n",
            "OUT017    1543\n",
            "OUT010     925\n",
            "OUT019     880\n",
            "Name: Outlet_Identifier, dtype: int64\n",
            "\n",
            "Medium    4655\n",
            "Small     3980\n",
            "High      1553\n",
            "Name: Outlet_Size, dtype: int64\n",
            "\n",
            "Tier 3    5583\n",
            "Tier 2    4641\n",
            "Tier 1    3980\n",
            "Name: Outlet_Location_Type, dtype: int64\n",
            "\n",
            "Supermarket Type1    9294\n",
            "Grocery Store        1805\n",
            "Supermarket Type3    1559\n",
            "Supermarket Type2    1546\n",
            "Name: Outlet_Type, dtype: int64\n",
            "\n",
            "train    8523\n",
            "test     5681\n",
            "Name: source, dtype: int64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOyCpuGv2MuJ"
      },
      "source": [
        "data[\"Item_Fat_Content\"].replace(\"low fat\",\"Low Fat\",inplace=True)\n",
        "data[\"Item_Fat_Content\"].replace(\"LF\",\"Low Fat\",inplace=True)\n",
        "data[\"Item_Fat_Content\"].replace(\"reg\",\"Regular\",inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAMTb52_edDI"
      },
      "source": [
        "Replacing low fat and LF with Low Fat/replacing reg with Regular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4zKvCja2qXq",
        "outputId": "0e1e2eeb-3682-4943-f654-9125d5db1283"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Item_Identifier                 0\n",
              "Item_Weight                  2439\n",
              "Item_Fat_Content                0\n",
              "Item_Visibility                 0\n",
              "Item_Type                       0\n",
              "Item_MRP                        0\n",
              "Outlet_Identifier               0\n",
              "Outlet_Establishment_Year       0\n",
              "Outlet_Size                  4016\n",
              "Outlet_Location_Type            0\n",
              "Outlet_Type                     0\n",
              "Item_Outlet_Sales            5681\n",
              "source                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeXbfaf1euN_"
      },
      "source": [
        "As per aboveb result null values are present in Item_Weight and Outlet_Size are numerical value which one can replace by mean and mode according to distrubutions of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "IxwMGmRT1yfg",
        "outputId": "a61488db-669d-45f8-94fc-dc3bfa4bad5a"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data['Item_Weight'],kde=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f672981a810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRWWlEjafezX"
      },
      "source": [
        "Item_weight is not normally distrubuted hence it will be replace by Median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "kvOyoW-S4d3_",
        "outputId": "397489cf-7880-4caa-cbd3-50e1b57a7b29"
      },
      "source": [
        "sns.histplot(data['Item_Outlet_Sales'],kde=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f671dcb94d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyRHIdRNfuRQ"
      },
      "source": [
        "Item_Outlet_Sales is not normally distrubuted hence it will be replace by Median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDvU-QTX5lF0"
      },
      "source": [
        "data['Outlet_Size']=data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0])\n",
        "data['Item_Weight']=data['Item_Weight'].fillna(data['Item_Weight'].median())\n",
        "data['Item_Outlet_Sales']=data['Item_Outlet_Sales'].fillna(data['Item_Outlet_Sales'].median())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp1GTpcof1Jj"
      },
      "source": [
        "As aboveb fill Null value of numberical by median and categorical values by Mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUpH5TFs4nP5",
        "outputId": "4ad224f3-d694-4785-b85b-663c8254dc91"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Item_Identifier              0\n",
              "Item_Weight                  0\n",
              "Item_Fat_Content             0\n",
              "Item_Visibility              0\n",
              "Item_Type                    0\n",
              "Item_MRP                     0\n",
              "Outlet_Identifier            0\n",
              "Outlet_Establishment_Year    0\n",
              "Outlet_Size                  0\n",
              "Outlet_Location_Type         0\n",
              "Outlet_Type                  0\n",
              "Item_Outlet_Sales            0\n",
              "source                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQX7-fpvgHQr"
      },
      "source": [
        "Now there are no any Null vales are present in dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "sU9OhBpb7PJO",
        "outputId": "0f626a48-8926-4b65-8868-830214702097"
      },
      "source": [
        "df_bigmart=pd.get_dummies(data,columns=[\"Item_Fat_Content\",\"Item_Type\",\"Outlet_Location_Type\",\"Outlet_Size\",\"Outlet_Type\"])\n",
        "df_bigmart"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Identifier</th>\n",
              "      <th>Item_Weight</th>\n",
              "      <th>Item_Visibility</th>\n",
              "      <th>Item_MRP</th>\n",
              "      <th>Outlet_Identifier</th>\n",
              "      <th>Outlet_Establishment_Year</th>\n",
              "      <th>Item_Outlet_Sales</th>\n",
              "      <th>source</th>\n",
              "      <th>Item_Fat_Content_Low Fat</th>\n",
              "      <th>Item_Fat_Content_Regular</th>\n",
              "      <th>Item_Type_Baking Goods</th>\n",
              "      <th>Item_Type_Breads</th>\n",
              "      <th>Item_Type_Breakfast</th>\n",
              "      <th>Item_Type_Canned</th>\n",
              "      <th>Item_Type_Dairy</th>\n",
              "      <th>Item_Type_Frozen Foods</th>\n",
              "      <th>Item_Type_Fruits and Vegetables</th>\n",
              "      <th>Item_Type_Hard Drinks</th>\n",
              "      <th>Item_Type_Health and Hygiene</th>\n",
              "      <th>Item_Type_Household</th>\n",
              "      <th>Item_Type_Meat</th>\n",
              "      <th>Item_Type_Others</th>\n",
              "      <th>Item_Type_Seafood</th>\n",
              "      <th>Item_Type_Snack Foods</th>\n",
              "      <th>Item_Type_Soft Drinks</th>\n",
              "      <th>Item_Type_Starchy Foods</th>\n",
              "      <th>Outlet_Location_Type_Tier 1</th>\n",
              "      <th>Outlet_Location_Type_Tier 2</th>\n",
              "      <th>Outlet_Location_Type_Tier 3</th>\n",
              "      <th>Outlet_Size_High</th>\n",
              "      <th>Outlet_Size_Medium</th>\n",
              "      <th>Outlet_Size_Small</th>\n",
              "      <th>Outlet_Type_Grocery Store</th>\n",
              "      <th>Outlet_Type_Supermarket Type1</th>\n",
              "      <th>Outlet_Type_Supermarket Type2</th>\n",
              "      <th>Outlet_Type_Supermarket Type3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDA15</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.016047</td>\n",
              "      <td>249.8092</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>3735.1380</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DRC01</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.019278</td>\n",
              "      <td>48.2692</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>2009</td>\n",
              "      <td>443.4228</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FDN15</td>\n",
              "      <td>17.50</td>\n",
              "      <td>0.016760</td>\n",
              "      <td>141.6180</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>2097.2700</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FDX07</td>\n",
              "      <td>19.20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>182.0950</td>\n",
              "      <td>OUT010</td>\n",
              "      <td>1998</td>\n",
              "      <td>732.3800</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCD19</td>\n",
              "      <td>8.93</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.8614</td>\n",
              "      <td>OUT013</td>\n",
              "      <td>1987</td>\n",
              "      <td>994.7052</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14199</th>\n",
              "      <td>FDB58</td>\n",
              "      <td>10.50</td>\n",
              "      <td>0.013496</td>\n",
              "      <td>141.3154</td>\n",
              "      <td>OUT046</td>\n",
              "      <td>1997</td>\n",
              "      <td>1794.3310</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14200</th>\n",
              "      <td>FDD47</td>\n",
              "      <td>7.60</td>\n",
              "      <td>0.142991</td>\n",
              "      <td>169.1448</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>2009</td>\n",
              "      <td>1794.3310</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14201</th>\n",
              "      <td>NCO17</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.073529</td>\n",
              "      <td>118.7440</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>2002</td>\n",
              "      <td>1794.3310</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14202</th>\n",
              "      <td>FDJ26</td>\n",
              "      <td>15.30</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>214.6218</td>\n",
              "      <td>OUT017</td>\n",
              "      <td>2007</td>\n",
              "      <td>1794.3310</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14203</th>\n",
              "      <td>FDU37</td>\n",
              "      <td>9.50</td>\n",
              "      <td>0.104720</td>\n",
              "      <td>79.7960</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>2002</td>\n",
              "      <td>1794.3310</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14204 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Item_Identifier  ...  Outlet_Type_Supermarket Type3\n",
              "0               FDA15  ...                              0\n",
              "1               DRC01  ...                              0\n",
              "2               FDN15  ...                              0\n",
              "3               FDX07  ...                              0\n",
              "4               NCD19  ...                              0\n",
              "...               ...  ...                            ...\n",
              "14199           FDB58  ...                              0\n",
              "14200           FDD47  ...                              0\n",
              "14201           NCO17  ...                              0\n",
              "14202           FDJ26  ...                              0\n",
              "14203           FDU37  ...                              0\n",
              "\n",
              "[14204 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRXrV2fygliv"
      },
      "source": [
        "we have dataset which have non numeric columns and it needs to be converted to numeric\n",
        "These three categorical colums has been converted in to one hot encoding.This is done so that ML model is able to process it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNI8lXJs-JWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "19667440-4106-424b-e29a-74f746a824b3"
      },
      "source": [
        "df_item_outlet=df_bigmart[[\"Item_Identifier\",\"Outlet_Identifier\",\"source\"]]\n",
        "df_item_outlet"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Identifier</th>\n",
              "      <th>Outlet_Identifier</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDA15</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DRC01</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FDN15</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FDX07</td>\n",
              "      <td>OUT010</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCD19</td>\n",
              "      <td>OUT013</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14199</th>\n",
              "      <td>FDB58</td>\n",
              "      <td>OUT046</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14200</th>\n",
              "      <td>FDD47</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14201</th>\n",
              "      <td>NCO17</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14202</th>\n",
              "      <td>FDJ26</td>\n",
              "      <td>OUT017</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14203</th>\n",
              "      <td>FDU37</td>\n",
              "      <td>OUT045</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14204 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Item_Identifier Outlet_Identifier source\n",
              "0               FDA15            OUT049  train\n",
              "1               DRC01            OUT018  train\n",
              "2               FDN15            OUT049  train\n",
              "3               FDX07            OUT010  train\n",
              "4               NCD19            OUT013  train\n",
              "...               ...               ...    ...\n",
              "14199           FDB58            OUT046   test\n",
              "14200           FDD47            OUT018   test\n",
              "14201           NCO17            OUT045   test\n",
              "14202           FDJ26            OUT017   test\n",
              "14203           FDU37            OUT045   test\n",
              "\n",
              "[14204 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YnpQ91LhHPJ"
      },
      "source": [
        "store item identifier ,outlet identifier and source in variable df_item_outlet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-LJzyshh2K_"
      },
      "source": [
        "df_bigmart[\"Outlet_Establishment_Year\"]=2013-df_bigmart[\"Outlet_Establishment_Year\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KEk3RKviSpd"
      },
      "source": [
        "we can covert outlet establishment year to howold is outlet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv832pxy-8jg"
      },
      "source": [
        "df_bigmart[\"Outlet__Years_of_operation\"]=df_bigmart[\"Outlet_Establishment_Year\"]\n",
        "df_bigmart.drop(columns=[\"Outlet_Establishment_Year\"],inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Eu6nnaKiaA9"
      },
      "source": [
        "Made a column \"Outlet__Years_of_operation\" and drop \"Outlet_Establishment_Year\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc8tA8aQ_EJS",
        "outputId": "d2643442-f523-49da-b512-a792aede2009"
      },
      "source": [
        "cols_to_be_checked=[\"Item_MRP\",\"Item_Visibility\",\"Item_Weight\",\"Outlet__Years_of_operation\"]\n",
        "for col in df_bigmart.skew().index:\n",
        "    if col in cols_to_be_checked:\n",
        "        print(\"Skewness of column {} is: {}\".format(col,df_bigmart.skew().loc[col]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skewness of column Item_Weight is: 0.13471142395276792\n",
            "Skewness of column Item_Visibility is: 1.1951751774587889\n",
            "Skewness of column Item_MRP is: 0.13072836040225863\n",
            "Skewness of column Outlet__Years_of_operation is: 0.3964651900863859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NL_o8Kxim8x"
      },
      "source": [
        "As per aboveb result found skewnes in data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl06zREx_KvP"
      },
      "source": [
        "import numpy as np\n",
        "df_bigmart.skew()\n",
        "for col in df_bigmart.skew().index:\n",
        "    if col in cols_to_be_checked:\n",
        "        if df_bigmart.skew().loc[col]>0.5:\n",
        "            df_bigmart[col]=np.sqrt(df_bigmart[col])\n",
        "        if df_bigmart.skew().loc[col]<-0.5:\n",
        "            df_bigmart[col]=np.cbrt(df_bigmart[col])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx1mQnqNi1FB"
      },
      "source": [
        "Removed skewness of data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHgAWW5i_eJe",
        "outputId": "f9c209b3-379f-4ea0-b2ac-58627393bfa7"
      },
      "source": [
        "for col in df_bigmart.skew().index:\n",
        "    if col in cols_to_be_checked:\n",
        "        print(\"Skewness of column {} is: {}\".format(col,df_bigmart.skew().loc[col]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skewness of column Item_Weight is: 0.13471142395276792\n",
            "Skewness of column Item_Visibility is: -0.0967582787285686\n",
            "Skewness of column Item_MRP is: 0.13072836040225863\n",
            "Skewness of column Outlet__Years_of_operation is: 0.3964651900863859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMZSgSNNi8xp"
      },
      "source": [
        "Aboveb columns skewness has been also removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIub_37M_icP"
      },
      "source": [
        "df_bigmart.drop(columns=[\"Item_Identifier\",\"Outlet_Identifier\"],inplace=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SweOCe2jGyP"
      },
      "source": [
        "droped (\"Item_Identifier\",\"Outlet_Identifier\",\"source\") from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvSwXfIMAPuS",
        "outputId": "d7a8bf9a-1b49-412d-87f8-1c7160075cbd"
      },
      "source": [
        "df_train=df_bigmart.loc[df_bigmart[\"source\"]==\"train\"]\n",
        "df_test=df_bigmart.loc[df_bigmart[\"source\"]==\"test\"]\n",
        "df_test.reset_index(drop=True,inplace=True)\n",
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales',\n",
            "       'source', 'Item_Fat_Content_Low Fat', 'Item_Fat_Content_Regular',\n",
            "       'Item_Type_Baking Goods', 'Item_Type_Breads', 'Item_Type_Breakfast',\n",
            "       'Item_Type_Canned', 'Item_Type_Dairy', 'Item_Type_Frozen Foods',\n",
            "       'Item_Type_Fruits and Vegetables', 'Item_Type_Hard Drinks',\n",
            "       'Item_Type_Health and Hygiene', 'Item_Type_Household', 'Item_Type_Meat',\n",
            "       'Item_Type_Others', 'Item_Type_Seafood', 'Item_Type_Snack Foods',\n",
            "       'Item_Type_Soft Drinks', 'Item_Type_Starchy Foods',\n",
            "       'Outlet_Location_Type_Tier 1', 'Outlet_Location_Type_Tier 2',\n",
            "       'Outlet_Location_Type_Tier 3', 'Outlet_Size_High', 'Outlet_Size_Medium',\n",
            "       'Outlet_Size_Small', 'Outlet_Type_Grocery Store',\n",
            "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Supermarket Type2',\n",
            "       'Outlet_Type_Supermarket Type3', 'Outlet__Years_of_operation'],\n",
            "      dtype='object')\n",
            "Index(['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales',\n",
            "       'source', 'Item_Fat_Content_Low Fat', 'Item_Fat_Content_Regular',\n",
            "       'Item_Type_Baking Goods', 'Item_Type_Breads', 'Item_Type_Breakfast',\n",
            "       'Item_Type_Canned', 'Item_Type_Dairy', 'Item_Type_Frozen Foods',\n",
            "       'Item_Type_Fruits and Vegetables', 'Item_Type_Hard Drinks',\n",
            "       'Item_Type_Health and Hygiene', 'Item_Type_Household', 'Item_Type_Meat',\n",
            "       'Item_Type_Others', 'Item_Type_Seafood', 'Item_Type_Snack Foods',\n",
            "       'Item_Type_Soft Drinks', 'Item_Type_Starchy Foods',\n",
            "       'Outlet_Location_Type_Tier 1', 'Outlet_Location_Type_Tier 2',\n",
            "       'Outlet_Location_Type_Tier 3', 'Outlet_Size_High', 'Outlet_Size_Medium',\n",
            "       'Outlet_Size_Small', 'Outlet_Type_Grocery Store',\n",
            "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Supermarket Type2',\n",
            "       'Outlet_Type_Supermarket Type3', 'Outlet__Years_of_operation'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjPKuQw7jlRZ"
      },
      "source": [
        "Seprated the train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDm_Qt54AcGH",
        "outputId": "fee37860-9df8-4327-bfbd-1378472e6ca3"
      },
      "source": [
        "df_test.drop(columns=[\"Item_Outlet_Sales\"],inplace=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9acK5R_kEKn"
      },
      "source": [
        "\n",
        "Droped the Item_Outlet_Sales from test dataset as that is the o/p variable that needs to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-zxclpLAsaq",
        "outputId": "f7837e30-8c1e-47e9-d66e-201a75708105"
      },
      "source": [
        "df_train.drop(columns=[\"source\"],inplace=True)\n",
        "df_test.drop(columns=[\"source\"],inplace=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xtBuuvEkWlB"
      },
      "source": [
        "Droped source column from df_train and df_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcRo-HWrAxp9"
      },
      "source": [
        "df_x=df_train.drop(columns=[\"Item_Outlet_Sales\"])\n",
        "y=df_train[[\"Item_Outlet_Sales\"]]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D-sLZSPkeZA"
      },
      "source": [
        "seprated input and output from df_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNDXdLxA198"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(df_x)\n",
        "x=pd.DataFrame(x,columns=df_x.columns)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7rUzXvwkrWX"
      },
      "source": [
        "Made every column to common scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frAeWVQKlHbr"
      },
      "source": [
        "### function of  random stat which gives maximum r2_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZC-95nxA7ci"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "def maxr2_score(regr,df_x,y):\n",
        "    max_r_score=0\n",
        "    for r_state in range(42,90):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(df_x, y,random_state = r_state,test_size=0.20)\n",
        "        regr.fit(x_train,y_train)\n",
        "        y_pred = regr.predict(x_test)\n",
        "        r2_scr=r2_score(y_test,y_pred)\n",
        "        print(\"r2 score corresponding to \",r_state,\" is \",r2_scr)\n",
        "        if r2_scr>max_r_score:\n",
        "            max_r_score=r2_scr\n",
        "            final_r_state=r_state\n",
        "    print(\"max r2 score corresponding to \",final_r_state,\" is \",max_r_score)\n",
        "    return final_r_state"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVogzJfdlTGE"
      },
      "source": [
        "### Function which evaluates the model using cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjX6jhxWBCN_"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "def model_evaluation(model,x,y):\n",
        "    c_scores=cross_val_score(model,x,y,cv=5,scoring=\"r2\")\n",
        "    print(\"Mean r2 score for regressor: \",c_scores.mean())\n",
        "    print(\"standard deviation in r2 score for regressor: \",c_scores.std())\n",
        "    print(c_scores)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dngjDNTOlcJu"
      },
      "source": [
        "### Lets use pca to reduce the dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDgI7hRSBOmg",
        "outputId": "7984b2ee-5fa6-49a5-eb1c-5dd239c46030"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=23)\n",
        "x_pca=pca.fit_transform(x)\n",
        "print(\"vraiance :{}\".format(np.sum(pca.explained_variance_ratio_)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vraiance :0.9480292259026457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1RgHO6pljry"
      },
      "source": [
        "### Lets use decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXXS5v_BUYX",
        "outputId": "ac45196c-9ba6-488e-9968-8cc506372347"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "dtr=DecisionTreeRegressor()\n",
        "r_state=maxr2_score(dtr,x_pca,y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score corresponding to  42  is  0.16326960861683026\n",
            "r2 score corresponding to  43  is  0.16693781950727926\n",
            "r2 score corresponding to  44  is  0.07169257436762877\n",
            "r2 score corresponding to  45  is  0.11816677296883371\n",
            "r2 score corresponding to  46  is  0.051337471256287515\n",
            "r2 score corresponding to  47  is  0.12515240985416187\n",
            "r2 score corresponding to  48  is  0.19265065733641507\n",
            "r2 score corresponding to  49  is  0.13277228093289284\n",
            "r2 score corresponding to  50  is  0.1179057425110952\n",
            "r2 score corresponding to  51  is  0.13442711940060992\n",
            "r2 score corresponding to  52  is  0.09654467787820742\n",
            "r2 score corresponding to  53  is  0.05456636172392104\n",
            "r2 score corresponding to  54  is  0.17941737551235537\n",
            "r2 score corresponding to  55  is  0.16525108197311278\n",
            "r2 score corresponding to  56  is  0.11634066837086199\n",
            "r2 score corresponding to  57  is  0.1598937616686369\n",
            "r2 score corresponding to  58  is  0.10630862066496605\n",
            "r2 score corresponding to  59  is  0.08163862595761473\n",
            "r2 score corresponding to  60  is  0.19575588285053547\n",
            "r2 score corresponding to  61  is  0.07393667800425274\n",
            "r2 score corresponding to  62  is  0.14324451851598852\n",
            "r2 score corresponding to  63  is  0.13310075605136484\n",
            "r2 score corresponding to  64  is  0.21547446038189655\n",
            "r2 score corresponding to  65  is  0.1881908698457213\n",
            "r2 score corresponding to  66  is  0.13336535497013735\n",
            "r2 score corresponding to  67  is  0.19201121098457563\n",
            "r2 score corresponding to  68  is  0.07901637290620078\n",
            "r2 score corresponding to  69  is  0.07996220612091465\n",
            "r2 score corresponding to  70  is  0.15769907074552403\n",
            "r2 score corresponding to  71  is  0.16321496056176243\n",
            "r2 score corresponding to  72  is  0.15018752388443812\n",
            "r2 score corresponding to  73  is  0.12955289282367788\n",
            "r2 score corresponding to  74  is  -0.006356102891461379\n",
            "r2 score corresponding to  75  is  0.162161244007209\n",
            "r2 score corresponding to  76  is  0.19791011577022743\n",
            "r2 score corresponding to  77  is  0.1338998951082454\n",
            "r2 score corresponding to  78  is  0.08697885375651082\n",
            "r2 score corresponding to  79  is  0.214750869533041\n",
            "r2 score corresponding to  80  is  0.1822746571683873\n",
            "r2 score corresponding to  81  is  0.1604045183877031\n",
            "r2 score corresponding to  82  is  0.1918489612232953\n",
            "r2 score corresponding to  83  is  0.13466392837890362\n",
            "r2 score corresponding to  84  is  0.18895116866635253\n",
            "r2 score corresponding to  85  is  0.13541498070196534\n",
            "r2 score corresponding to  86  is  0.10126457377384712\n",
            "r2 score corresponding to  87  is  0.1397922392268336\n",
            "r2 score corresponding to  88  is  0.0694987979088506\n",
            "r2 score corresponding to  89  is  0.0838765773707314\n",
            "max r2 score corresponding to  64  is  0.21547446038189655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGcnm99JlpmJ"
      },
      "source": [
        "### lets use random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR96oAeiBahS",
        "outputId": "8a4d7037-6c76-4f10-d971-6d48f3438ff5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rfr=RandomForestRegressor()\n",
        "parameters = {\"n_estimators\":[10,100,500]}\n",
        "clf = GridSearchCV(rfr, parameters, cv=5,scoring=\"r2\")\n",
        "clf.fit(x_pca,y)\n",
        "clf.best_params_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 500}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcPui4a-Bj_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9bb2d5-d96a-494e-dbcb-a2fb194b1cb6"
      },
      "source": [
        "rfr=RandomForestRegressor(n_estimators=500)\n",
        "r_state=maxr2_score(rfr,x_pca,y)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score corresponding to  42  is  0.5493418501793685\n",
            "r2 score corresponding to  43  is  0.5782361348865779\n",
            "r2 score corresponding to  44  is  0.5531668829958245\n",
            "r2 score corresponding to  45  is  0.5362890000962469\n",
            "r2 score corresponding to  46  is  0.5011659756804686\n",
            "r2 score corresponding to  47  is  0.5452199293215931\n",
            "r2 score corresponding to  48  is  0.5557479231220936\n",
            "r2 score corresponding to  49  is  0.5531064664898592\n",
            "r2 score corresponding to  50  is  0.5392148255701468\n",
            "r2 score corresponding to  51  is  0.525511158520426\n",
            "r2 score corresponding to  52  is  0.5242047733169495\n",
            "r2 score corresponding to  53  is  0.5241746490074691\n",
            "r2 score corresponding to  54  is  0.5642548378524173\n",
            "r2 score corresponding to  55  is  0.5606708850438221\n",
            "r2 score corresponding to  56  is  0.5355775940072669\n",
            "r2 score corresponding to  57  is  0.5472962363153626\n",
            "r2 score corresponding to  58  is  0.5416449676806874\n",
            "r2 score corresponding to  59  is  0.5409454578174431\n",
            "r2 score corresponding to  60  is  0.5759518784451041\n",
            "r2 score corresponding to  61  is  0.5419185658676695\n",
            "r2 score corresponding to  62  is  0.5573332608508236\n",
            "r2 score corresponding to  63  is  0.542466443166367\n",
            "r2 score corresponding to  64  is  0.5381521773611839\n",
            "r2 score corresponding to  65  is  0.5601348910296367\n",
            "r2 score corresponding to  66  is  0.5465172984720992\n",
            "r2 score corresponding to  67  is  0.5672714681517932\n",
            "r2 score corresponding to  68  is  0.5257418869684919\n",
            "r2 score corresponding to  69  is  0.5578530236656496\n",
            "r2 score corresponding to  70  is  0.5495060223978097\n",
            "r2 score corresponding to  71  is  0.551224480376165\n",
            "r2 score corresponding to  72  is  0.5803028710147646\n",
            "r2 score corresponding to  73  is  0.5275425848218891\n",
            "r2 score corresponding to  74  is  0.5178642991772469\n",
            "r2 score corresponding to  75  is  0.5732902869022481\n",
            "r2 score corresponding to  76  is  0.5761842223473819\n",
            "r2 score corresponding to  77  is  0.5489206000625452\n",
            "r2 score corresponding to  78  is  0.52346600600706\n",
            "r2 score corresponding to  79  is  0.5517299637856525\n",
            "r2 score corresponding to  80  is  0.5460849563410888\n",
            "r2 score corresponding to  81  is  0.5420691265465678\n",
            "r2 score corresponding to  82  is  0.5617287386408167\n",
            "r2 score corresponding to  83  is  0.5241935025922643\n",
            "r2 score corresponding to  84  is  0.573710534742258\n",
            "r2 score corresponding to  85  is  0.5470128452007961\n",
            "r2 score corresponding to  86  is  0.5375769434252362\n",
            "r2 score corresponding to  87  is  0.5244187025555095\n",
            "r2 score corresponding to  88  is  0.5399979421724572\n",
            "r2 score corresponding to  89  is  0.5603515649318654\n",
            "max r2 score corresponding to  72  is  0.5803028710147646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipiiYzaBlxcM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oU9OBprlxgA"
      },
      "source": [
        "### lets check KNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOwPfjAiDyMf",
        "outputId": "76d39b46-73b7-4504-fb39-987a15350d97"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knr=KNeighborsRegressor()\n",
        "parameters = {\"n_neighbors\":range(2,30)}\n",
        "clf = GridSearchCV(knr, parameters, cv=5,scoring=\"r2\")\n",
        "clf.fit(x_pca, y)\n",
        "clf.best_params_"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CToDdJC-MOh5",
        "outputId": "c95380b4-2193-4d39-9b7c-1ddee0596a9f"
      },
      "source": [
        "knr=KNeighborsRegressor(n_neighbors=8)\n",
        "r_state=maxr2_score(knr,x_pca,y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score corresponding to  42  is  0.5024503497893338\n",
            "r2 score corresponding to  43  is  0.5000794185225176\n",
            "r2 score corresponding to  44  is  0.49877293838417036\n",
            "r2 score corresponding to  45  is  0.483163329716524\n",
            "r2 score corresponding to  46  is  0.4528665820231246\n",
            "r2 score corresponding to  47  is  0.46163872649734694\n",
            "r2 score corresponding to  48  is  0.4942474356641995\n",
            "r2 score corresponding to  49  is  0.5118540089429913\n",
            "r2 score corresponding to  50  is  0.48684002342009514\n",
            "r2 score corresponding to  51  is  0.48189287390752356\n",
            "r2 score corresponding to  52  is  0.4932885082478994\n",
            "r2 score corresponding to  53  is  0.4610777468483389\n",
            "r2 score corresponding to  54  is  0.5023740540230146\n",
            "r2 score corresponding to  55  is  0.5019781659399363\n",
            "r2 score corresponding to  56  is  0.48234027774768196\n",
            "r2 score corresponding to  57  is  0.46217565955746365\n",
            "r2 score corresponding to  58  is  0.48488933906153286\n",
            "r2 score corresponding to  59  is  0.4914636335431105\n",
            "r2 score corresponding to  60  is  0.5063070775361773\n",
            "r2 score corresponding to  61  is  0.49134241455495997\n",
            "r2 score corresponding to  62  is  0.5013647239131673\n",
            "r2 score corresponding to  63  is  0.49932310515890566\n",
            "r2 score corresponding to  64  is  0.47887817615684614\n",
            "r2 score corresponding to  65  is  0.49295905851765764\n",
            "r2 score corresponding to  66  is  0.45991947524500176\n",
            "r2 score corresponding to  67  is  0.5190485170078344\n",
            "r2 score corresponding to  68  is  0.4731281636462602\n",
            "r2 score corresponding to  69  is  0.482238718421213\n",
            "r2 score corresponding to  70  is  0.5047816914544846\n",
            "r2 score corresponding to  71  is  0.497200833306634\n",
            "r2 score corresponding to  72  is  0.5027867784847229\n",
            "r2 score corresponding to  73  is  0.4427093637741024\n",
            "r2 score corresponding to  74  is  0.47512074030621454\n",
            "r2 score corresponding to  75  is  0.49496418468802017\n",
            "r2 score corresponding to  76  is  0.5010557645656677\n",
            "r2 score corresponding to  77  is  0.4771780820792527\n",
            "r2 score corresponding to  78  is  0.44504975555451054\n",
            "r2 score corresponding to  79  is  0.49925878325214357\n",
            "r2 score corresponding to  80  is  0.48019993727106736\n",
            "r2 score corresponding to  81  is  0.4769234879678693\n",
            "r2 score corresponding to  82  is  0.49604421337611726\n",
            "r2 score corresponding to  83  is  0.498895421374948\n",
            "r2 score corresponding to  84  is  0.5099415569708126\n",
            "r2 score corresponding to  85  is  0.5176176578142413\n",
            "r2 score corresponding to  86  is  0.47376169613496344\n",
            "r2 score corresponding to  87  is  0.4628558304056589\n",
            "r2 score corresponding to  88  is  0.5040502407889971\n",
            "r2 score corresponding to  89  is  0.49301887107046394\n",
            "max r2 score corresponding to  67  is  0.5190485170078344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgjsiogfl4b6"
      },
      "source": [
        "### Lets use SVM regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7izwmsMMbRB",
        "outputId": "08d3af51-bea9-4c95-e61f-eb62d2b12ff2"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "svr=SVR()\n",
        "parameters={\"kernel\":[\"linear\", \"poly\", \"rbf\"],\"C\":[0.001,0.01,0.1,1,10]}\n",
        "clf = GridSearchCV(svr, parameters, cv=5,scoring=\"r2\")\n",
        "clf.fit(x_pca,y)\n",
        "clf.best_params_"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkDTeKYsMgJd",
        "outputId": "22675a12-ab7d-4bf3-fcf9-ecac6f3eccc6"
      },
      "source": [
        "svr=SVR(kernel=\"linear\",C=10)\n",
        "r_state=maxr2_score(svr,x_pca,y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score corresponding to  42  is  0.4924008957922199\n",
            "r2 score corresponding to  43  is  0.48627350046814743\n",
            "r2 score corresponding to  44  is  0.49880016238204283\n",
            "r2 score corresponding to  45  is  0.4908755723351079\n",
            "r2 score corresponding to  46  is  0.47832681548093336\n",
            "r2 score corresponding to  47  is  0.48185299218623356\n",
            "r2 score corresponding to  48  is  0.48174439053978246\n",
            "r2 score corresponding to  49  is  0.4815905524451658\n",
            "r2 score corresponding to  50  is  0.4811980821090379\n",
            "r2 score corresponding to  51  is  0.4790552186787512\n",
            "r2 score corresponding to  52  is  0.49650121217904364\n",
            "r2 score corresponding to  53  is  0.47758238590439606\n",
            "r2 score corresponding to  54  is  0.49023748409038537\n",
            "r2 score corresponding to  55  is  0.47638658500787545\n",
            "r2 score corresponding to  56  is  0.45551400477408\n",
            "r2 score corresponding to  57  is  0.4667324025857478\n",
            "r2 score corresponding to  58  is  0.49294009332908895\n",
            "r2 score corresponding to  59  is  0.4738113903340192\n",
            "r2 score corresponding to  60  is  0.498596580993687\n",
            "r2 score corresponding to  61  is  0.48331285915172406\n",
            "r2 score corresponding to  62  is  0.5050686678477249\n",
            "r2 score corresponding to  63  is  0.4957376771674251\n",
            "r2 score corresponding to  64  is  0.464786198816715\n",
            "r2 score corresponding to  65  is  0.4890602237464359\n",
            "r2 score corresponding to  66  is  0.47993400331308944\n",
            "r2 score corresponding to  67  is  0.4888720955320288\n",
            "r2 score corresponding to  68  is  0.49102795394988785\n",
            "r2 score corresponding to  69  is  0.49320451664456955\n",
            "r2 score corresponding to  70  is  0.4857046735727304\n",
            "r2 score corresponding to  71  is  0.4818642018065922\n",
            "r2 score corresponding to  72  is  0.4962769969595291\n",
            "r2 score corresponding to  73  is  0.4802474161964775\n",
            "r2 score corresponding to  74  is  0.47563308209437294\n",
            "r2 score corresponding to  75  is  0.48417135837086855\n",
            "r2 score corresponding to  76  is  0.514183325931777\n",
            "r2 score corresponding to  77  is  0.4842945952042894\n",
            "r2 score corresponding to  78  is  0.47602249793614926\n",
            "r2 score corresponding to  79  is  0.5041910368735264\n",
            "r2 score corresponding to  80  is  0.5077460883868689\n",
            "r2 score corresponding to  81  is  0.49186382301264997\n",
            "r2 score corresponding to  82  is  0.4785056130870944\n",
            "r2 score corresponding to  83  is  0.4670462787156938\n",
            "r2 score corresponding to  84  is  0.48503427007846756\n",
            "r2 score corresponding to  85  is  0.4775503063390225\n",
            "r2 score corresponding to  86  is  0.48420187642480883\n",
            "r2 score corresponding to  87  is  0.4821763839974219\n",
            "r2 score corresponding to  88  is  0.49887677949587494\n",
            "r2 score corresponding to  89  is  0.5019492807054433\n",
            "max r2 score corresponding to  76  is  0.514183325931777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgDewfy8l-yh"
      },
      "source": [
        "### Now lets do cross_validation of various models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm4_Euf5VbsJ",
        "outputId": "9c1e9159-9518-4779-a5b3-710d80078e12"
      },
      "source": [
        "print(\"DECISION TREE REGRESSOR\\n\\n\")\n",
        "model_evaluation(dtr,x_pca,y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DECISION TREE REGRESSOR\n",
            "\n",
            "\n",
            "Mean r2 score for regressor:  0.12616363516247037\n",
            "standard deviation in r2 score for regressor:  0.02877761688659727\n",
            "[0.13865584 0.0850466  0.09935918 0.15831727 0.14943928]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jngjEHAZW1rn",
        "outputId": "dfade838-ea4b-4582-d874-a54984b72fc6"
      },
      "source": [
        "print(\"RANDOM FOREST REGRESSOR\\n\\n\")\n",
        "model_evaluation(rfr,x_pca,y)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RANDOM FOREST REGRESSOR\n",
            "\n",
            "\n",
            "Mean r2 score for regressor:  0.541817934878112\n",
            "standard deviation in r2 score for regressor:  0.016297979471873114\n",
            "[0.55397138 0.52383684 0.52052012 0.55116152 0.55959981]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqfE4SUaW5Qw",
        "outputId": "e5f5111e-c468-4ed4-c7ba-7eb39c0fbba2"
      },
      "source": [
        "print(\"SVM REGRESSOR\\n\\n\")\n",
        "model_evaluation(svr,x_pca,y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM REGRESSOR\n",
            "\n",
            "\n",
            "Mean r2 score for regressor:  0.4851613210158575\n",
            "standard deviation in r2 score for regressor:  0.004671737280230764\n",
            "[0.49091579 0.48710041 0.48558217 0.4766796  0.48552864]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3NFMeJemGsT"
      },
      "source": [
        "### Based on above r2 scores arandom forest and SVM are performing better than other two\n",
        "### lets make model using SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMuljhf0XDW8"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_pca, y,random_state = 76,test_size=0.20)\n",
        "svr.fit(x_train,y_train)\n",
        "y_pred = svr.predict(x_test)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1c-vbQlmOXG"
      },
      "source": [
        "### Lets find the rmse and r2_score using sklearn.metrics for SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMOr05iRXGSL",
        "outputId": "c01aef55-c62f-4ed5-a6be-99b9a02648a8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"RMSE is: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "print(\"r2_score is: \",r2_score(y_test,y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE is:  1178.6312209671353\n",
            "r2_score is:  0.514183325931777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJj8zPE9XZ3w"
      },
      "source": [
        "import pickle\n",
        "import joblib\n",
        "joblib.dump(svr,'big_mart_svr.obj')\n",
        "pickle.dump(svr,open('big_mart_svr.pkl','wb'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdlKBJ4SnsDN"
      },
      "source": [
        "Save model with both library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esdC7eNMnNdY"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}